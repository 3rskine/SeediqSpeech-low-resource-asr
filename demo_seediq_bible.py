import soundfile
from espnet2.bin.asr_inference import Speech2Text
import os
import sys
import torch

# --- è·¯å¾‘è¨­å®š ---
# 1. è²å­¸æ¨¡å‹ (ASR) - ä¸è®Š
asr_model_path = "exp/asr_seediq_upper/valid.acc.ave.pth"
asr_config_path = "exp/asr_seediq_upper/config.yaml"

# 2. èªè¨€æ¨¡å‹ (LM) - æ›æˆè–ç¶“ç‰ˆï¼
lm_model_path = "exp/lm_train_lm_seediq_bible_en_bpe5000/valid.loss.ave.pth"
lm_config_path = "exp/lm_train_lm_seediq_bible_en_bpe5000/config.yaml"

# é˜²å‘†æª¢æŸ¥
if not os.path.exists(lm_model_path):
    # å˜—è©¦æ‰¾ best (æœ‰äº›ç‰ˆæœ¬å­˜æˆ min.pth)
    fallback = "exp/lm_train_lm_seediq_bible_en_bpe5000/valid.loss.min.pth"
    if os.path.exists(fallback):
        lm_model_path = fallback
    else:
        print(f"âŒ æ‰¾ä¸åˆ°è–ç¶“ç‰ˆ LM æ¨¡å‹: {lm_model_path}")
        sys.exit(1)

print(f"ğŸš€ è¼‰å…¥è–ç¶“åŠ å¼·ç‰ˆæ¨¡å‹...\nASR: {asr_model_path}\nLM:  {lm_model_path}")

try:
    # åˆå§‹åŒ–
    speech2text = Speech2Text(
        asr_train_config=asr_config_path,
        asr_model_file=asr_model_path,
        lm_train_config=lm_config_path,
        lm_file=lm_model_path,
        device="cpu",
        minlenratio=0.0,
        maxlenratio=0.0,
        ctc_weight=0.5,    # å† è»åƒæ•¸: å¼·è²å­¸
        lm_weight=0.2,     # å† è»åƒæ•¸: å¼±èªè¨€è¼”åŠ©
        beam_size=10,
        batch_size=0
    )
except Exception as e:
    print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
    sys.exit(1)

def recognize_file(wav_file):
    if not os.path.exists(wav_file):
        print(f"âŒ æ‰¾ä¸åˆ°éŸ³æª”: {wav_file}")
        return

    try:
        speech, rate = soundfile.read(wav_file)
        print(f"\nğŸ§ æ­£åœ¨è½ (With Bible LM): {wav_file}")
        
        nbests = speech2text(speech)
        text, *_ = nbests[0]
        
        print("-" * 30)
        print(f"ğŸ—£ï¸  çµæœ: {text}")
        print("-" * 30)
    except Exception as e:
        print(f"âŒ æ¨è«–å¤±æ•—: {e}")

if __name__ == "__main__":
    recognize_file("test.wav")
