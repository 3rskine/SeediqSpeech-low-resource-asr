import soundfile
from espnet2.bin.asr_inference import Speech2Text
import os
import sys
import torch

# --- è·¯å¾‘è¨­å®š ---
asr_model_path = "exp/asr_seediq_upper/valid.acc.ave.pth"
asr_config_path = "exp/asr_seediq_upper/config.yaml"
# ä½¿ç”¨å¹³å‡æ¬Šé‡ (æ›´ç©©å®š)
lm_model_path = "exp/lm_train_lm_seediq_en_bpe5000/valid.loss.ave.pth"
lm_config_path = "exp/lm_train_lm_seediq_en_bpe5000/config.yaml"

# æª¢æŸ¥æª”æ¡ˆ
if not os.path.exists(lm_model_path):
    print(f"âŒ æ‰¾ä¸åˆ° LM æ¨¡å‹: {lm_model_path}")
    sys.exit(1)

print(f"ğŸš€ è¼‰å…¥æ¨¡å‹ä¸­...\nASR: {asr_model_path}\nLM:  {lm_model_path}")

try:
    # åˆå§‹åŒ– (åŠ å…¥ LM è¨­å®š)
    speech2text = Speech2Text(
        asr_train_config=asr_config_path,
        asr_model_file=asr_model_path,
        lm_train_config=lm_config_path,
        lm_file=lm_model_path,
        device="cpu", # å¼·åˆ¶ CPU é¿å… OOM
        minlenratio=0.0,
        maxlenratio=0.0,
        ctc_weight=0.3,
        lm_weight=0.3, # LM æ¬Šé‡ (é—œéµåƒæ•¸)
        beam_size=10,
        batch_size=0
    )
except Exception as e:
    print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
    sys.exit(1)

def recognize_file(wav_file):
    if not os.path.exists(wav_file):
        print(f"âŒ æ‰¾ä¸åˆ°éŸ³æª”: {wav_file}")
        return

    try:
        speech, rate = soundfile.read(wav_file)
        print(f"\nğŸ§ æ­£åœ¨è½ (With LM): {wav_file}")
        
        nbests = speech2text(speech)
        text, *_ = nbests[0]
        
        print("-" * 30)
        print(f"ğŸ—£ï¸  çµæœ: {text}")
        print("-" * 30)
    except Exception as e:
        print(f"âŒ æ¨è«–å¤±æ•—: {e}")

if __name__ == "__main__":
    recognize_file("test.wav")
